<!DOCTYPE HTML>
<html>
	<head>
		<title>About me - Akshath Varugeese</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/timeline.css" />	
	</head>
	<body class="is-preload">

		<!-- Header -->
			<section id="header">
				<header style='padding-bottom: 0px;'>
					<span class="image avatar"><img src="images/Akshath.jpg" alt="" /></span>
					<h1 id="logo" style="margin-bottom: 10px;"><a href="#">Akshath Varugeese</a></h1>
					<ul class="icons" style="margin-bottom: 0px;">
						<li><a href="https://www.linkedin.com/in/akshath-varugeese/" class="icon brands fa-linkedin"><span class="label">Facebook</span></a></li>
						<li><a href="https://www.youtube.com/channel/UCU-0H3m6JgpC6mEiy_vXELg" class="icon brands fa-youtube"><span class="label">YouTube</span></a></li>
						<li><a href="https://github.com/akshath123" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li><a href="#" class="icon fas fa-edit"><span class="label">Blog</span></a></li>						
					</ul>					
				</header>
				<nav id="nav">
					<ul>
						<li><a href="#about_me" class="active">About Me</a></li>
						<li><a href="#skills">Skills</a></li>
						<li><a href="#work_experience">Work Experience</a></li>
						<li><a href="#research_papers">Research Papers</a></li>
						<li><a href="#education">Education</a></li>
						<li><a href="#accomplishments">Achivements</a></li>
						<li><a href="#hobbies">Hobbies</a></li>
					</ul>
				</nav>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<!-- About Me -->
							<section id="about_me">
								<div class="container">
									<header class="major" style="margin-bottom: 0px; text-align: justify;">
										<h2>Greetings!</h2>
										<p style = "margin-bottom: 20px;">About me</p>										
										I am a <b>Machine Learing</b> and <b>Computer Vision Engineer</b> based in 
										Bangalore. I am currently working in 
										<b><a href = "https://www.capillarytech.com/products/smart-store-plus/?utm_campaign=Capillary_India_Brand&utm_medium=cpc&utm_source=google&Lead_Source=Adwords&PPC&adposition=&searchkeyword=capillary&technologies&matchtype=b&device=c&locationID=1007809&Campaign=undefined">
										Smart Store+ </a></b>
										division at 
										<b><a href = "https://www.capillarytech.com/?searchkeyword=capillary%20technologies&matchtype=b&adposition=&device=c&locationID=1007809&utm_source=google&utm_medium=cpc&utm_campaign=Capillary_India_Brand&Lead_Source=Adwords%20PPC&gclid=Cj0KCQjwu7OIBhCsARIsALxCUaOusCbOHTtNEPyNMe_1kE69xKVe7hL0CAetZ5z4JLIYqJS2eRwtiVoaArWIEALw_wcB">
										Capillary Technologies Pvt Ltd.</a></b> <br><br>
										&ensp; &ensp; &ensp; &ensp;
										Previously, I was a Computer Vision Intern at Capillary Technologies and at an early stage 
										startup <b><a href = "http://sdtech.io/">SDTECH (Formely known as Studio Diseno)</a></b>. I started writting the blog 
										<a href="http://html5up.net">Machine Learning Cognitio</a> to solidfy my understanding 
										of computer vision and machine learning while helping others to learn about.										
									</header>
									<div class = "row">
										<div class="col">&ensp;</div>
									</div>
									<div class = "row">
										<div class="col-9">&ensp;</div>
										<div class="col">
											<div class="float-right"><a href="#" class="button icon solid">Contact Me</a></div>
											<!-- <div class="float-right"><a href="#" class="button primary icon solid fa-download">Resume</a></div> -->
										</div>											
									</div>									
								</div>
							</section>

						<!-- Skills -->
							<section id="skills">
								<div class="container" style = "text-align: justify;text-justify: inter-word;">
									<h3>Skills</h3>
									<p>Below are some of my skills, and I'am always looking to learn more.</p>

									<h5>Computer Vision</h5>
									<p >
										<span class="image left">
											<img src="images/computer_vision.jpeg" alt="" height="100" width = "100"/></span>
											I have signifcant research and industrial experience in developing Computer Vision applications
											using tools like <b>OpenCV</b>, <b>scikit-geometery</b> and <b>scikit-image</b> in C++ and Python. 
											The applications developed tested my knowledge on tradional computer vision, image processing  
											and computational geometery.											
									</p>									

									<h5>Machine Learning</h5>
									<p>
										<span class="image left">
											<img src="images/machine_learning.jpeg" alt="" height="100" width = "100"/></span>
											My typical day at work include developing machine learning applications using 
											<b>TensorFlow</b>, <b>Keras</b> and <b>scikit-learn</b>. Furthermore, I have performed data 
											manipulation, data analysis and visulization using tools like <b>pandas</b>, <b>matplotlib</b> and <b>seaborn</b>.
											I also have experience using <b>PySpark</b> for distributed data processing. 											
									</p>
									
									<h5>Python</h5>
									<p >
										<span class="image left">
											<img src="images/python.jpeg" alt="" height="100" width = "100"/></span>
											Over the past 5.5 years, I've had extensive experience with Python in the course of research, classwork, personal projects 
											and at work. The Machine Learning applications developed by me in Python have used <b>Object Oriented Programming (OOPs)</b> has it's
											programming paradigm and <b><a href="https://docs.python.org/3/library/typing.html">typing</a></b> as it's support for type hints. 
									</p>
									
									<h5>C++</h5>
									<p >
										<span class="image left">
											<img src="images/c_plus_plus.png" alt="" height="100" width = "100"/></span>
											My experience in C++ comes from developing computer vision applications for edge devices using OpenCV and practising 
											competative programming on platforms such as LeetCode, Hackerrank, Hackearth and InterviewBit. I have also compiled and 
											generated libraries using <b>cmake</b>.
									</p>
									
									<h5>CUDA Python & C++</h5>
									<p >
										<span class="image left">
											<img src="images/cuda.png" alt="" height="100" width = "100"/></span>
											I have developed High Performance Compute <b>(HPC)</b> applications using <strong>CUDA C++ API</strong> to perform high speed and complex feature extraction 
											from images to train ML algorithms. My notable work in HPC is to bring down the time required for extracting features from 1 million images 
											to <strong>2 hours</strong> from <strong>11 hours</strong> on a single 1060 GTX GPU. Furthermore, I also have experinece in using 
											<strong>Numba</strong> &#38 <strong>OpenMP</strong>.											
									</p>

									<h5>TensorFlow</h5>
									<p >
										<span class="image left">
											<img src="images/tensorflow.png" alt="" height="100" width = "100"/></span>
											 I have a significant experience using TensorFlow for developing and training <b>deep neural networks (DNNs)</b> for 
											 computer vision applications. While working for Capillary, I have built custom layers and pruned DNNs for reducing the 
											 model complexity. Furthermore, I have <b>quantized deep neural networks</b> using <b>post training quantization</b> and 
											 <b>quantization aware training</b> for deploying models on edge devices.

									</p>									

									<h5>AirFlow</h5>
									<p >
										<span class="image left">
											<img src="images/airflow.png" alt="" height="100" width = "100"/></span>
											I have used AirFlow as an Orchestration tool for <b>MLOps</b> to automate and managing workflows such as  
											data validation before training an AI model, training the machine learning model at specific intervals, batch processing,
											and inference. 
											  								
									</p>
									<br>									
									
									<h5>MongoDB</h5>
									<p >
										<span class="image left">
											<img src="images/mongodb.jpeg" alt="" height="100" width = "100"/></span>
											I have some experience of using MongoDB as backend database from developing machine learning applications, 
											all the applications use Python's MongoDB driver. Furthermore, I also have experience in utilizing the aggregate 
											framework provided by MongoDB for document transformation and data analysis.
									</p>

									<br>
									
									<h5>SQL</h5>
									<p >
										<span class="image left">
											<img src="images/SQL.png" alt="" height="100" width = "100"/></span>
											My experience in SQL comes from reading Capillary's massive database using PySpark to perform data validation, 
											and feature engineering	for creating the train, test and validation set for Machine Learning models.  										
									</p>									
									<br>
								</div>

							</section>

							<!-- Work Experience -->
							<section id="work_experience">
								<div class='container'>
									<ul style='list-style: circle; text-align: justify;'>
										<li>
											<p>April 2021 - Present</p>
											<div class = "">
												<h2>Machine Learning Engineer - II</h2>
												<h3>Capillary Technologies Pvt Ltd.</h3>	
												<h4>Work done so far:</h4>							
												<ul>
													<li style='margin-bottom: 15px;'>														
														<b>Automated the generation of fundamental matrix</b> using facial key points as it's correspondence
														coordinates between pair of images, each image in a pair taken from on of the two cameras having 
														different prespective views. <b>Reduced the camera calibration time from 1 hour to 5 mins for an Edge AI product (Customer Visual Profile).</b>
													</li>
													<li style='margin-bottom: 15px;'>
														Developed a <strong>segmentation algorithm</strong> using <strong>OpenPose (Deep Neural Network)</strong> and Watershed algorithm to 
														create segmentation maps to segment people in an image for <strong>edge computing</strong>.
													</li>
													<li style='margin-bottom: 15px;'>
														<!-- Developed workflow management pipeline using <strong>AirFlow</strong> to schedule data validation notebooks 
														hosted on DataBricks before training Machine Learing Models. -->
														Developed &#38; architected Data Validation Framework (DVF) for the product <a href='https://www.capillarytech.com/blog/tag/omnichannel-data-capture/'>Artificial Intelligence Retail Assistant <strong>(AiRA)</strong></a>
														which is a core orchestration service logic based on Directed Acyclic Graph (DAG) to schedule data validation notebooks
														hosted at DataBricks using <strong>AirFlow</strong>. <a href='https://medium.com/capillary-tech/aira-a-worthy-proponent-of-capflow-a58453157fdf'><i class="fa fa-link"></i></a>

													</li>
												</ul>
												<h4>Responsibilities:</h4>
												<ul>
													<li>Lead the research &#38; development of the POC for computer vision applications in SmartStore+ team.</li>
													<li>Mentoring interns and Junior Machine Learning Engineers in their progress and overlooking the work distribution.</li>													
													<li>Ownership of maintaining and enhancing the data validation framework which is used to validate data before training machine learning models.</li>
												</ul>
												<h4>Technologies Used:</h4>												
												<p>TensorFlow, AirFlow, OpenCV, Python, PySpark</p>
											</div>
										</li>

										<li>
										<p>June 2019 - March 2021</p>
										<div class = "">
											<h2>Machine Learning Engineer - I</h2>
											<h3>Capillary Technologies Pvt Ltd.</h3>
											<h4>Work Done:</h4>
											<ul>
												<li style='margin-bottom: 15px;'>
													Developed an AI-product to calculate the customer's time spent (or Dwell time) in a store using two modules person re-identification and a matching algorithm. 
													<ul style="list-style-type: square; margin-bottom: 5px;">
														<li>The person re-identification is a deep learning model developed using <strong>ResNet-50 backend</strong> and a <strong>triplet loss objective function.</strong></li>
														<li>The matching of embedding generated using ResNet 50 model was done using <strong>Hungarian assignment</strong> as well as <strong>K-Nearest Neighbors</strong>.</li>
														<li>The model was served using <strong>TensorFlow serving</strong> on Amazon EIA.</li>														
													</ul>
												</li>

												<li style='margin-bottom: 15px;'>
													Developed two versions of badge classification model using deep learning models with <strong>MobileNetV1</strong> and <strong>MobileNetV2</strong> backend. The model selection
													was done using ROC and AUC metric. 
												</li>
												<li style='margin-bottom: 15px;'>
													Developed face recognition model with different deep learning backends namely <strong>ResNet101, MobileNetV2</strong> and <strong>ResNet50</strong> with arc-face has it's loss function.
												</li>
												<li style='margin-bottom: 15px;'>
													Performed <strong>post training quantization</strong> and <strong>quantization aware training</strong> on the above mentioned models to inference on edge devices such as Raspberry Pi, Google Coral Dev board and 
													Google Coral USB Accelerator using TensorFlow.
												</li>
												<li style='margin-bottom: 15px;'>
													Used <strong>Epipolar Geometery</strong> to assign the same visitor ID (UUID) to a customer detected in two cameras having two different prespective views. Furthermore, used <strong>Intersection Over Union (IOU)</strong> for eliminating 
													occluded customers on the edge device. 
												</li>
												<li style='margin-bottom: 15px;'>
													Developed a document detection algorithm to detect a document in an image for an OCR product. <strong>The document detection algorithm obtained 0.93 as it's Jaccard Index.</strong>													
												</li>
												<li style='margin-bottom: 15px;'>
													Performed <strong>Exploratory Data Analysis (EDA)</strong> on client's customer behaviour towards the loyalty program provided by Capillary Technologies Pvt Ltd.
												</li>												
											</ul>
											<h4>Responsibilities:</h4>
											<ul>
												<li>Mentoring interns and overlooking the work distribution.</li>													
												<li>Ownership of three AI micro-services and two device modules.</li>
											</ul>
											<h4>Technologies Used:</h4>												
											<p>TensorFlow, OpenCV, Python, Scikit-learn, Scipy</p>											
										</div>
										</li>
										
										<li>
											<p>January 2019 - May 2019</p>
											<div class = "">
												<h2>Computer Vision Intern</h2>
												<h3>Capillary Technologies Pvt Ltd.</h3>
												<h4>Work Done:</h4>
												<ul>
													<li style='margin-bottom: 15px;'>														
														<strong>Developed Revolver YOLO</strong>: Person detection algorithm for fish-eye lenses, traditional off the shelf deep learning models don't detect person which have been distorted i.e. roated due to 
														FOV being 360 degree or 280 degree. To counter this we rotate (using rotational matrix) equally intrevaled patches of the image and make it upright perform detection and rotate it back to it's original position.
													</li>
													<li style='margin-bottom: 15px;'>
														Developed a logic similar to background subtraction to discard mannequins detected as person by <strong>YOLO</strong>. 
													</li>
													<li>
														Developed YOLO-Lite in TensorFlow from scratch and trained the model using an in-house dataset for person detection. The model performance was 21 mAP for the test set and gave 5 FPS on Raspberry Pi 3 B+. 
													</li>
												</ul>																								
											
												<h4>Technologies Used:</h4>
												<p>OpenCV, TensorFlow, Python, C++</p>
											</div>											
										</li>										
									</ul>
								</div>
							</section>			

							<!-- Research Papers -->
							<section id="research_papers">
								<div class="container">
									<h3>Research Papers</h3>
									<div class="row">
										<ol>										
											<li>
												<header>
													<h4>EarNet: Biometric Embeddings for End to End Person Authentication System Using Transient Evoked Otoacoustic Emission Signal</h4>
													<p>Journal: Neural Processing Letters | Springer | Status: Paper Accepted</p>
												</header>
												<p style='text-align: justify;'>
													Transient Evoked Otoacoustic Emissions (TEOAE) are a class of otoacoustic emissions 
													that are generated by the cochlea in response to an external													
													stimulus. The TEOAE signals exhibit characteristics unique to an individual, and
													are therefore considered as a potential biometric modality. Unlike conventional													
													modalities, TEOAE is immune to replay and falsification attacks due to its implicit liveliness detection feature. In this paper, we propose an efficient deep neural													
													network architecture, EarNet, to learn the appropriate filters for non-stationary													
													(TEOAE) signals, which can reveal individual uniqueness and long-term reproducibility. EarNet is inspired by Googleâ€™s FaceNet. Furthermore, the embeddings													
													generated by EarNet, in the Euclidean space, are such that they reduce intrasubject variability while capturing inter-subject variability, as visualized using													
													t-SNE. The embeddings from EarNet are used for identification and verification
													tasks. The K-Nearest Neighbour classifier gives <b>identification accuracies of 99.21%
													and 99.42% for the left and right ear</b>, respectively, which are highest among the
													machine learning algorithms explored in this work. The verification using Pearson
													correlation on the embeddings performs with an <b>EER of 0.581% and 0.057% for
													the left and right ear</b>, respectively, scoring better than all other techniques. <b>Fusion
													strategy yields an improved identification accuracy of 99.92%</b>. The embeddings
													generalize well on subjects that are not part of the training, and hence EarNet is
													scalable on any new larger dataset.
												</p>
											</li>
											<li>
												<header>
													<h4>H. U. B - Eye, Hearing using Bone Conduction and seeing through DNN</h4>
													<p>Conference: International Conference on Advanced Computing and Communications (ADCOM 2018)</p>
												</header>
												<p style='text-align: justify;'>
													The paper proposes a device capable of making the
													lives of visually impaired easier. The device encompasses an image
													recognition using deep learning (convolutional neural network)
													unit coupled with the novel idea of the bone conduction system,
													which can be mounted on the sunglasses of the visually impaired.
													The whole process allows two-channel hearing enabling people
													to hear regular as well as the intended audio. Instead of air, the
													sound is propagated through the bone in the form of vibration
													and is sent to cochlea through a membrane. The proposed
													system takes an image from a mounted camera, classifies it
													with a dedicated processor and sends the audio signal through a
													Bluetooth channel to the bone conduction transducer so that the
													user can hear through the system what is in front of him. The
													system is able to recognize the input image using deep learning
													and give an audio output directly to the eardrum of the user.
												</p>
											</li>										
										</ol>
									</div>
								</div>
							</section>	
							
							<!-- Education -->
							<section id="education">
								<div class="container">
									<h3>Education</h3>
									<div class="features">
										<article>
											<a href="#" class="image"><img src="images/vit_full.png" alt="" /></a>
											<div class="inner">
												<h4>Vellore Institute of Technology, Chennai</h4>
												<p>
													MTech Integrated in Software Engineering <br>
													(5 years program)<br>
													CGPA: 9.32/10.0
												</p>
											</div>
										</article>
										<p style='text-align: justify;'>
											My education in Software Engineering focused from strong software engineering princeples such as SDLC, Software Requirement Specificatin (SRS), Requirement Specification Document etc. to 
											good programming practices in Python, C++, JAVA, .NET and Computer Networks. Furthermore, we had vigrous courses on Data Structures &#38; Algorithms, Linear Algebra, Probability &#38; Statistics 
											and Calculus. 
										</p>
										
										<h4>Activities</h4>
										<p style='text-align: justify;'>
											<span class="image left">
												<img src="images/technocrats.jpeg" alt="" height="100" width = "100"/>
											</span>
											Was part of <a href="https://www.facebook.com/technocratsrobotics/">Technocrats Robotics Team</a> for two years which participated in various robotics competitions across the nation. This team had approximately 25 students from Mechanical, Electrical &#38; Electronics,
											Computer Science and Management. I was heading the computer science team for the year 2017 and all the divisions in 2018. My core contributions are given below, 
											<ul>
												<li>Administrated four students to program one manual robot.</li>
												<li>Programmed IMU sensor to control the yaw, pitch, roll of the bot using a joystick interfaced with Arduino board.</li>
												<li>Programmed a robot having LSA08 sensor for line following using image processing algorithm in OpenCV on BeagleBone Black Board.</li>
												<li>Developed an algorithm for controlling the RPM of the DC motor using rotary encoder of the bot.</li>
											</ul>		
											<iframe class='left' width="300" height="200" src="https://www.youtube.com/embed/IWe_ecrxInI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>																																											
											<iframe class='left' width="300" height="200" src="https://www.youtube.com/embed/U970_3PV-ps" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>											
										</p>
									</div>
								</div>
							</section>
							
						<!-- Accomplishments -->
							<section id="accomplishments">
								<div class="container">
									<h3>Achivements</h3>
									<p>A few of my notable achivements are given below,</p>
									<div class="features">
										<article>
											<span class="image"><img src="images/rank_holder.jpeg" alt="" width="588" height="220"/></span>
											<div class="inner">
												<!-- <h4>Ranked 6th in a batch of 221 students </h4> -->
												<h4>Meritorious Award</h4>
												<p style='text-align: justify;'>
													I achieved rank 6<sup>th</sup> in the class of 221 students for the batch of 2014-2019 M.Tech Software Engineering 
												   (5 years Integrated) program with the CGPA of 9.32/10.0 towards the end. The award for the achievement 
												   was given to me by <a href="https://en.wikipedia.org/wiki/Smriti_Irani"><strong>Smriti Irani</strong>, </a> Minister of Women and Child Development in the Union Cabinet of India since May 2019.
												</p>
											</div>
										</article>
										<article>
											<span class="image"><img src="images/data_science_hackathon.png" alt="" /></span>
											<div class="inner">
												<h4>I<sup>st</sup> place in Data Science Hackathon</h4>
												<p style='text-align: justify;'>
													Among 73 teams me and my teammate won 1<sup>st</sup> place in the Data Science Hackathon 
													conducted by Velloe Institutue of Technology, Chennai. The competition was to predict the 
													taxi fare given a set of features, we built a XGBoost based model to arrive at the lowest 
													RMSE in the competition.
												</p>
											</div>
										</article>										
										<article>
											<span class="image"><img src="images/iot_makethon.jpeg" alt="" /></span>
											<div class="inner">
												<h4>III<sup>rd</sup> place in IOT Makeathon</h4>
												<p style='text-align: justify;'>
													Ideated and developed the product "Just in Time" which is an IOT based product for real time 
													accident detection and notifying the helping bodies. The accident detection was done using real data 
													collected from accelerometer and then classifying them using Dynamic Time Wrapping (DTW) Algorithm. 
												</p>
											</div>
										</article>										
										<article>
											<span class="image"><img src="images/best_project_award.png" alt="" /></span>
											<div class="inner">
												<h4>Best Project Award</h4>
												<p style='text-align: justify;'>
													Developed a Game in C++ using graphics.h in first semester for the course "Programming in C++". I had developed a 
													carom coin matching game 
												</p>
											</div>
										</article>																			
									</div>
								</div>
							</section>

						<!-- Hobbies -->
							<section id="hobbies">
								<div class="container">
									<h3>Hobbies</h3>
									<div class="features">																		
									<article>
										<!-- <span class="image"><img src="images/best_project_award.png" alt="" /></span> -->
										<span class="image"><img src="images/tennis.jpg"width = "300px" height="300px"/></span>
										<div class="inner">
											<h4>Tennis</h4>
											<p style='text-align: justify;'>
												I have developed huge passion for <strong>Tennis</strong> from elementary school days by knocking tennis balls on the walls of the house for several hours 
												and breaking few of mom's favourite crockery, followed by being reprimand for the same (But, I never stopped though! &#128540;) . My Tennis ideal 
												growing up and still date has been one and only the great Roger Federer. I have always played Tennis as a hobby in my school, colleges and 
												even now as a recretional activity. I have won till date two small competitions in Tennis, one held in my Highschool days and one held for the 
												wards of Oil and Natural Gas Corporation (My dad's was an employee here). 
										</div>
									</article>	
									<article>
										<!-- <span class="image"><img src="images/best_project_award.png" alt="" /></span> -->
										<span class="image"><img src="images/chess.png"width = "300px" height="300px"/></span>
										<div class="inner">
											<h4>Chess</h4>
											<p style='text-align: justify;'>
												Being a <strong>Chess</strong> player's son (yep, my dad, <a href="https://ratings.fide.com/profile/5000114">Varugeese Koshy</a> is an Iternational Master (IM) with a FIDE Rating 2117.) So, at least I have to play Chess as a hobby but 
												ended being second most favourite sport. I even ended up getting a <a href="https://ratings.fide.com/profile/5083346">1335</a> as FIDE rating. I was more focused on enjoying the game rather than wining 
												or losing during Chess tournaments. These day's I don't play open tournaments but I do play Chess Online time to time. For Accomplishments in Chess, 
												I have won a Zonal and some state level competitions in Chess during my school days.
										</div>
									</article>																		
								</div>
							</section> 
				
					</div>

				<!-- Footer -->
					<section id="footer" style="padding-top: 15px;padding-bottom: 25px;height: 42px;">
						<div class="container" >
							<ul class="copyright">
								<li>&copy; <strong>Akshath Varugeese. All rights reserved.</strong></li>
							</ul>
						</div>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>